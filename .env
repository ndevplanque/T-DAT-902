# Configuration pour le scraping et l'utilisation du dump
ENABLE_SCRAPER=false      # Mettez 'true' pour activer le scraper, 'false' pour utiliser le dump
USE_MONGODB_DUMP=false     # Mettez 'true' pour utiliser le dump MongoDB (si ENABLE_SCRAPER=false)

# Options du scraper (utilisées uniquement si ENABLE_SCRAPER=true)
MAX_VILLES=0           # 0 pour scraper toutes les villes, sinon limiter au nombre spécifié
MAX_WORKERS=8          # Nombre de workers pour le scraping parallèle
TEST_MODE=false        # Mode test avec seulement quelques villes
UPDATE_MODE=true      # Mode mise à jour (ne scrape que les nouvelles villes)

########################################
# Configuration pour properties-importer
########################################

POSTGRES_DB=gis_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

CSV_DVF_PATH=/properties/CSV_DVF

# Spark config pour l'import immobilier
PYSPARK_PYTHON=/usr/bin/python3.9
PYSPARK_DRIVER_PYTHON=/usr/bin/python3.9
SPARK_JARS=/opt/bitnami/spark/jars/postgresql-42.7.4.jar
