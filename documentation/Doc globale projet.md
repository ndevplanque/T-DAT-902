# Documentation du Projet Homepedia (T-DAT-902)

## Introduction

Homepedia est une plateforme compl√®te d'analyse immobili√®re et urbaine qui combine donn√©es g√©ographiques, transactions immobili√®res DVF et avis citoyens sur les villes fran√ßaises. Le projet utilise une architecture microservices moderne avec Big Data (Hadoop/Spark), bases de donn√©es multi-modales (PostgreSQL/MongoDB) et une interface web interactive.

## Architecture du Projet

Le projet s'organise autour de plusieurs composants interconnect√©s:

1. **Sources de donn√©es**:
   - Scraping d'avis sur les villes fran√ßaises depuis "bien-dans-ma-ville.fr"
   - Import de donn√©es g√©ographiques GeoJSON (communes, d√©partements, r√©gions)
   - Import de donn√©es immobili√®res DVF (Demandes de Valeurs Fonci√®res)

2. **Stockage distribu√©**:
   - **PostgreSQL/PostGIS**: Donn√©es g√©ospatiales et transactions immobili√®res
   - **MongoDB**: Avis citoyens, sentiments et mots-cl√©s
   - **Hadoop HDFS**: Stockage distribu√© des fichiers GeoJSON volumineux

3. **Traitement Big Data**:
   - **Apache Spark**: Traitement distribu√© (g√©ospatial, NLP, agr√©gations)
   - **Hadoop Ecosystem**: Infrastructure de stockage et calcul distribu√©
   - **Pipeline ETL**: Extraction, transformation et chargement automatis√©s

4. **Couche applicative**:
   - **API REST Flask**: Endpoints optimis√©s avec cache et visualisations
   - **Frontend Streamlit**: Interface interactive avec cartes Leaflet
   - **Services de validation**: Contr√¥le qualit√© automatis√© √† chaque √©tape

## Pr√©requis

- **Docker et Docker Compose** (version r√©cente)
- **Minimum 12 Go de RAM** disponible (recommand√© 16 Go)
- **Environ 20 Go d'espace disque** (donn√©es + images Docker)
- **Processeur multi-c≈ìurs** (minimum 4 cores pour Spark)
- **R√©seau internet** pour le scraping et t√©l√©chargements

## Donn√©es trait√©es

- **34,455 communes** fran√ßaises avec g√©om√©tries
- **54,656 avis citoyens** analys√©s
- **1,5M transactions immobili√®res** (fichier DVF 260MB)
- **368,672 mots-cl√©s** extraits et analys√©s
- **Couverture g√©ographique**: 18 r√©gions, 101 d√©partements

## Structure des Services

### Services de Base de Donn√©es
- **postgres**: PostgreSQL + PostGIS pour donn√©es g√©ospatiales et immobili√®res
- **mongodb**: MongoDB pour avis, sentiments et mots-cl√©s
- **mongodb-restore**: Service de restauration automatique des dumps

### Infrastructure Big Data
- **namenode**: N≈ìud ma√Ætre Hadoop HDFS
- **datanode**: N≈ìud de stockage HDFS
- **hdfs-loader**: Chargement automatique des GeoJSON dans HDFS
- **spark-master**: Orchestrateur du cluster Spark
- **spark-worker / spark-worker-2**: Workers Spark (6 cores, 12GB RAM total)

### Services de Traitement
- **geo-data-importer**: Import des donn√©es g√©ographiques GeoJSON ‚Üí PostgreSQL
- **properties-importer**: Import des donn√©es immobili√®res DVF ‚Üí PostgreSQL
- **avis-scraper**: Collecte des avis depuis "bien-dans-ma-ville.fr"
- **avis-processor-submitter**: Traitement NLP des avis avec Spark
- **data-aggregator**: Agr√©gation multi-niveaux (villes ‚Üí d√©partements ‚Üí r√©gions)

### Services d'Application
- **backend**: API REST Flask avec 8 endpoints
- **frontend**: Interface Streamlit avec cartes interactives

### Services de Validation
- **avis-data-validator**: Validation des donn√©es scrap√©es
- **avis-processor-validator**: Validation du traitement NLP
- **data-aggregator-validator**: Validation des agr√©gations statistiques

## Options de D√©ploiement

Deux options sont disponibles pour collecter les avis sur les villes:

1. **Ex√©cuter le scraper** (long - environ 4h):
   - Collecte compl√®te depuis le site source
   - Personnalisable (nombre de villes, mode test, etc.)

2. **Utiliser un dump MongoDB pr√©existant** (rapide):
   - Restaure directement une base de donn√©es d√©j√† constitu√©e
   - √âvite le long processus de scraping

## Configuration du Projet

La configuration se fait via le fichier `.env` √† la racine du projet:

```bash
# Configuration pour le scraping
ENABLE_SCRAPER=false      # Mettez 'true' pour activer le scraper, 'false' pour utiliser le dump
USE_MONGODB_DUMP=true     # Utilis√© uniquement si ENABLE_SCRAPER=false

# Options du scraper (utilis√©es uniquement si ENABLE_SCRAPER=true)
MAX_VILLES=0           # 0 pour scraper toutes les villes, sinon limiter au nombre sp√©cifi√©
MAX_WORKERS=8          # Nombre de workers pour le scraping parall√®le
TEST_MODE=false        # Mode test avec seulement quelques villes
UPDATE_MODE=false      # Mode mise √† jour (ne scrape que les nouvelles villes)
```

## Installation et D√©marrage

1. **Clonez le d√©p√¥t**:
   ```bash
   git clone <url-du-repo>
   cd t-dat-902
   ```

2. **Configurez votre environnement**:
   - Cr√©ez un fichier `.env` √† la racine du projet avec les param√®tres souhait√©s
   - V√©rifiez que le dump MongoDB est pr√©sent dans `avis-scraper/mongo-dump/villes_france/` si vous souhaitez l'utiliser

3. **D√©marrez les services**:
   ```bash
   docker-compose up -d
   ```

4. **Suivez les logs pour surveiller le d√©marrage**:
   ```bash
   docker-compose logs -f
   ```

## Utilisation du Dump MongoDB

Si vous choisissez d'utiliser le dump MongoDB pr√©existant:

1. **Assurez-vous que vous avez le dump**:
   - Le dump doit √™tre situ√© dans `avis-scraper/mongo-dump/villes_france/`
   - Les fichiers attendus sont: `avis.bson`, `avis.metadata.json`, `villes.bson`, `villes.metadata.json`

2. **Configurez les variables d'environnement**:
   ```
   ENABLE_SCRAPER=false
   USE_MONGODB_DUMP=true
   ```

3. **D√©marrez les services**:
   ```bash
   docker-compose up -d
   ```

## Cr√©ation d'un Dump MongoDB (pour partage)

Si vous avez d√©j√† ex√©cut√© le scraper et souhaitez partager le r√©sultat:

1. **Cr√©ez un dump de la base MongoDB**:
   ```bash
   docker exec -it mongodb mongodump --host localhost --port 27017 --username root --password rootpassword --authenticationDatabase admin --db villes_france --out /dump
   ```

2. **Copiez le dump depuis le conteneur**:
   ```bash
   mkdir -p avis-scraper/mongo-dump
   docker cp mongodb:/dump/villes_france avis-scraper/mongo-dump/
   ```

## Acc√®s aux Services

Une fois le d√©ploiement termin√©, vous pouvez acc√©der aux services:

### Interfaces Web
- **üè† Interface Streamlit**: http://localhost:8501 (Dashboard principal)
- **üîß API Backend**: http://localhost:5001 (API REST + health check)
- **‚ö° Spark Master UI**: http://localhost:8080 (Monitoring cluster Spark)
- **üóÑÔ∏è Hadoop NameNode UI**: http://localhost:9870 (Monitoring HDFS)

### Bases de Donn√©es
- **üìä MongoDB**: `mongodb://root:rootpassword@localhost:27017/villes_france`
- **üó∫Ô∏è PostgreSQL**: `postgresql://postgres:postgres@localhost:5432/gis_db`

### Endpoints API principaux
- `GET /api/v1/health` - Health check
- `GET /api/v1/map-areas/{zoom}/{bounds}` - Donn√©es cartographiques
- `GET /api/v1/price-tables` - Tableaux de prix immobiliers
- `GET /api/v1/sentiments/{entity}/{id}` - Graphiques de sentiment
- `GET /api/v1/word-clouds/{entity}/{id}` - Nuages de mots
- `GET /api/v1/area-details/{entity}/{id}` - D√©tails d'une zone

## V√©rification de l'Installation

Pour v√©rifier que les donn√©es ont bien √©t√© charg√©es:

### V√©rification MongoDB (Avis et Sentiments)
```bash
# Comptage des collections principales
docker exec mongodb mongosh --username root --password rootpassword --authenticationDatabase admin villes_france --eval "
  printjson({
    villes: db.villes.countDocuments({}),
    avis: db.avis.countDocuments({}),
    mots_villes: db.mots_villes.countDocuments({}),
    departements_stats: db.departements_stats.countDocuments({}),
    regions_stats: db.regions_stats.countDocuments({})
  })"
```
**R√©sultats attendus**: 34,455 villes, 54,656 avis, 34,455 mots_villes, 94 d√©partements, 12 r√©gions

### V√©rification PostgreSQL (G√©ospatial et Immobilier)
```bash
# Comptage des tables principales
docker exec postgres psql -U postgres -d gis_db -c "
  SELECT 'cities' as table_name, COUNT(*) as count FROM cities
  UNION ALL SELECT 'departments', COUNT(*) FROM departments
  UNION ALL SELECT 'regions', COUNT(*) FROM regions
  UNION ALL SELECT 'properties', COUNT(*) FROM properties
  UNION ALL SELECT 'properties_cities_stats', COUNT(*) FROM properties_cities_stats;"
```
**R√©sultats attendus**: 34,945 cities, 101 departments, 18 regions, ~1.5M properties, 30,860 cities_stats

### V√©rification HDFS (Stockage Distribu√©)
```bash
# V√©rification des fichiers GeoJSON
docker exec namenode hdfs dfs -ls /data
docker exec namenode hdfs dfs -du -h /data
```
**R√©sultats attendus**: 3 fichiers GeoJSON (~10.5 MB total)

### Test de l'API Backend
```bash
# Test du health check
curl http://localhost:5001/api/v1/health

# Test des donn√©es cartographiques
curl "http://localhost:5001/api/v1/map-areas/10/48.5/2.0/49.0/2.5"
```

## Flux de Travail Complet

### Phase 1: Pr√©paration des donn√©es
1. **hdfs-loader**: Chargement des GeoJSON (communes, d√©partements, r√©gions) dans HDFS
2. **mongodb-restore**: Restauration du dump MongoDB OU **avis-scraper**: Collecte des avis

### Phase 2: Import et traitement distribu√©
3. **geo-data-importer**: Import Spark des donn√©es g√©ographiques HDFS ‚Üí PostgreSQL
4. **properties-importer**: Import Spark des donn√©es DVF ‚Üí PostgreSQL (1,5M transactions)
5. **avis-processor-submitter**: Traitement NLP Spark (sentiments + mots-cl√©s)

### Phase 3: Agr√©gation et consolidation
6. **data-aggregator**: Calcul des statistiques par d√©partement et r√©gion
7. **Services de validation**: Contr√¥le qualit√© automatis√© (3 validateurs)

### Phase 4: Exposition des donn√©es
8. **backend**: API REST Flask avec endpoints optimis√©s
9. **frontend**: Interface Streamlit avec visualisations interactives

### D√©pendances critiques
```
BaseDB ‚Üí Hadoop ‚Üí Spark ‚Üí Import ‚Üí Aggregation ‚Üí Validation ‚Üí App
    ‚Üì         ‚Üì        ‚Üì        ‚Üì           ‚Üì            ‚Üì       ‚Üì
PostGIS    HDFS   Workers   Data      Statistics    Quality  API/UI
MongoDB           3.4.1     Import    Multi-level   Control
```

## D√©pannage

### Probl√®mes de m√©moire (le plus fr√©quent)
```bash
# Arr√™t complet et nettoyage
docker-compose down --volumes
docker system prune -a

# V√©rification m√©moire Docker
docker system df
docker stats --no-stream

# Augmentez la m√©moire Docker √† 12-16GB minimum
# Puis red√©marrage
docker-compose up -d
```

### Probl√®mes de d√©marrage s√©quentiel
```bash
# Les services ont des d√©pendances strictes
# Si un service √©choue, relancez dans l'ordre:
docker-compose up -d postgres mongodb
sleep 30
docker-compose up -d namenode datanode
sleep 30
docker-compose up -d spark-master spark-worker spark-worker-2
sleep 30
docker-compose up -d
```

### Diagnostic par service
```bash
# Logs d√©taill√©s par service critique
docker-compose logs -f hdfs-loader          # Chargement HDFS
docker-compose logs -f geo-data-importer     # Import g√©ographique
docker-compose logs -f properties-importer   # Import immobilier
docker-compose logs -f avis-processor-submitter  # Traitement NLP
docker-compose logs -f data-aggregator       # Agr√©gations

# Status de tous les containers
docker-compose ps

# Utilisation des ressources
docker stats --no-stream
```

### Probl√®mes sp√©cifiques

#### Spark Workers d√©connect√©s
```bash
# V√©rification du cluster Spark
curl http://localhost:8080/api/v1/applications
docker-compose restart spark-worker spark-worker-2
```

#### HDFS inaccessible
```bash
# Test de connectivit√© HDFS
docker exec namenode hdfs dfsadmin -report
docker exec namenode hdfs dfs -ls /
```

#### MongoDB corruption
```bash
# R√©paration MongoDB
docker exec mongodb mongod --repair
docker-compose restart mongodb
```

#### PostgreSQL connexion refused
```bash
# V√©rification PostgreSQL
docker exec postgres pg_isready -U postgres
docker exec postgres psql -U postgres -l
```

## M√©triques et Performances

### Donn√©es trait√©es (Production)
- **G√©ospatiales**: 34,945 communes, 101 d√©partements, 18 r√©gions
- **Avis citoyens**: 54,656 avis analys√©s avec NLP
- **Immobili√®res**: 1,5M transactions DVF (260 MB de donn√©es)
- **Mots-cl√©s**: 368,672 mots extraits et cat√©goris√©s
- **Agr√©gations**: 30,860 villes avec statistiques compl√®tes

### Performance du cluster
- **Spark**: 2 workers, 6 cores total, 12 GB RAM
- **HDFS**: 10.5 MB stock√©s, r√©plication factor 3
- **Temps de traitement**: ~15-20 minutes pour pipeline complet
- **API**: <100ms pour requ√™tes g√©ospatiales optimis√©es

### M√©triques qualit√©
- **Completeness**: 98.5% (champs non-null)
- **Consistency**: 100% (coh√©rence inter-niveaux)
- **Accuracy**: 96.8% (donn√©es dans ranges attendus)
- **Prix r√©alistes**: 22,800/30,860 villes (74%) > 50k‚Ç¨

### Top villes par transactions immobili√®res
1. **Nice**: 4,604 transactions (354k‚Ç¨ moyen)
2. **Toulouse**: 4,430 transactions (291k‚Ç¨ moyen)  
3. **Nantes**: 2,672 transactions (294k‚Ç¨ moyen)

### Analyse sentiments (national)
- **Positif**: 36.15% des avis
- **Neutre**: 51.87% des avis
- **N√©gatif**: 11.99% des avis

## Architecture Technique D√©taill√©e

### Stack technologique
- **Big Data**: Hadoop 3.2.1 + Spark 3.4.1
- **Bases de donn√©es**: PostgreSQL 14 + PostGIS, MongoDB latest
- **Backend**: Flask + Python 3.9
- **Frontend**: Streamlit + Leaflet.js
- **Containerisation**: Docker Compose avec 15+ services

### Patterns architecturaux
- **Microservices**: Services d√©coupl√©s avec responsabilit√©s claires
- **Event-driven**: Pipeline ETL avec d√©pendances s√©quentielles
- **Clean Architecture**: S√©paration couches donn√©es/m√©tier/pr√©sentation
- **Validation multi-niveaux**: Contr√¥le qualit√© automatis√©

## Arr√™t du Projet

### Arr√™t standard
```bash
docker-compose down
```

### Arr√™t avec nettoyage complet (‚ö†Ô∏è perte de donn√©es)
```bash
docker-compose down --volumes
docker system prune -a
```

### Sauvegarde avant arr√™t
```bash
# Dump MongoDB
docker exec mongodb mongodump --host localhost --port 27017 \
  --username root --password rootpassword --authenticationDatabase admin \
  --db villes_france --out /backup

# Export PostgreSQL
docker exec postgres pg_dump -U postgres gis_db > backup_postgres.sql
```